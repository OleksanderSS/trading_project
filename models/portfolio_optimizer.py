#!/usr/bin/env python3
"""
Portfolio Optimization Module
–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ: Markowitz, Black-Litterman, Risk Parity, Hierarchical Risk Parity
"""

import pandas as pd
import numpy as np
import scipy.optimize as opt
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import logging
import warnings
warnings.filterwarnings('ignore')

from models.fama_french_factors import get_fama_french_factors
from models.hedge_fund_analyzer import calculate_performance_metrics

logger = logging.getLogger(__name__)


class PortfolioOptimizer:
    """
    –û–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ –∑ —Ä—ñ–∑–Ω–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    """
    
    def __init__(self):
        self.logger = logging.getLogger("PortfolioOptimizer")
        
        # –ú–µ—Ç–æ–¥–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        self.optimization_methods = [
            'markowitz',           # –ö–ª–∞—Å–∏—á–Ω–∞ mean-variance –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
            'min_variance',       # –ú—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—è –¥–∏—Å–ø–µ—Ä—Å—ñ—ó
            'max_sharpe',         # –ú–∞–∫—Å–∏–º—ñ–∑–∞—Ü—ñ—è Sharpe ratio
            'risk_parity',        # Risk parity (—Ä—ñ–≤–Ω–∏–π —Ä–∏–∑–∏–∫)
            'hrp',               # Hierarchical Risk Parity
            'black_litterman',    # Black-Litterman
            'equal_weight',       # –†—ñ–≤–Ω—ñ –≤–∞–≥–∏
            'inverse_volatility'   # –û–±–µ—Ä–Ω–µ–Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å
        ]
        
        # –û–±–º–µ–∂–µ–Ω–Ω—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        self.constraints = {
            'min_weight': 0.0,      # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞
            'max_weight': 1.0,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞
            'max_positions': 10,    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–∑–∏—Ü—ñ–π
            'turnover_limit': 0.5,  # –û–±–º–µ–∂–µ–Ω–Ω—è –æ–±–æ—Ä–æ—Ç—É
            'sector_limit': 0.3     # –û–±–º–µ–∂–µ–Ω–Ω—è –ø–æ —Å–µ–∫—Ç–æ—Ä–∞—Ö
        }
        
        self.logger.info("PortfolioOptimizer initialized")
    
    def calculate_returns(self, prices: pd.DataFrame) -> pd.DataFrame:
        """
        –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ —Ü—ñ–Ω
        
        Args:
            prices: DataFrame –∑ —Ü—ñ–Ω–∞–º–∏
            
        Returns:
            pd.DataFrame: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
        """
        try:
            returns = prices.pct_change().dropna()
            self.logger.info(f"Returns calculated: {len(returns)} observations, {len(returns.columns)} assets")
            return returns
        except Exception as e:
            self.logger.error(f"Error calculating returns: {e}")
            return pd.DataFrame()
    
    def calculate_covariance_matrix(self, returns: pd.DataFrame, method: str = 'sample') -> pd.DataFrame:
        """
        –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω—É –º–∞—Ç—Ä–∏—Ü—é
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            method: –ú–µ—Ç–æ–¥ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É ('sample', 'ledoit-wolf', 'shrinkage')
            
        Returns:
            pd.DataFrame: –ö–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
        """
        try:
            if method == 'sample':
                cov_matrix = returns.cov()
            elif method == 'ledoit-wolf':
                # Ledoit-Wolf shrinkage estimator
                n_assets = len(returns.columns)
                sample_cov = returns.cov()
                
                # Shrinkage intensity
                shrinkage = self._calculate_ledoit_wolf_shrinkage(returns)
                
                # Target (constant correlation)
                var_diag = np.diag(sample_cov)
                rho = np.mean(sample_cov.values[np.triu_indices_from(sample_cov.values, k=1)])
                target = rho * np.ones((n_assets, n_assets))
                np.fill_diagonal(target, var_diag)
                
                # Shrinkage estimator
                cov_matrix = (1 - shrinkage) * sample_cov + shrinkage * target
            else:
                cov_matrix = returns.cov()
            
            # Ensure positive definite
            cov_matrix = self._ensure_positive_definite(cov_matrix)
            
            self.logger.info(f"Covariance matrix calculated: method={method}")
            return cov_matrix
            
        except Exception as e:
            self.logger.error(f"Error calculating covariance matrix: {e}")
            return pd.DataFrame()
    
    def markowitz_optimization(self, returns: pd.DataFrame, 
                             risk_free_rate: float = 0.02,
                             target_return: float = None) -> Dict[str, any]:
        """
        Markowitz mean-variance –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            risk_free_rate: –ë–µ–∑—Ä–∏–∑–∏–∫–æ–≤–∞ —Å—Ç–∞–≤–∫–∞
            target_return: –¶—ñ–ª—å–æ–≤–∞ –¥–æ—Ö–æ–¥–Ω—ñ—Å—Ç—å (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            mu = returns.mean() * 252  # –†—ñ—á–Ω—ñ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            n_assets = len(mu)
            
            # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            def portfolio_variance(weights):
                return np.dot(weights.T, np.dot(cov_matrix.values, weights))
            
            def portfolio_return(weights):
                return np.dot(weights.T, mu)
            
            # –û–±–º–µ–∂–µ–Ω–Ω—è
            constraints = [
                {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # –°—É–º–∞ –≤–∞–≥ = 1
            ]
            
            if target_return is not None:
                constraints.append(
                    {'type': 'eq', 'fun': lambda x: portfolio_return(x) - target_return}
                )
            
            # –ú–µ–∂—ñ –≤–∞–≥
            bounds = tuple((self.constraints['min_weight'], self.constraints['max_weight']) 
                          for _ in range(n_assets))
            
            # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –≤–∞–≥–∏ (—Ä—ñ–≤–Ω—ñ)
            x0 = np.array([1/n_assets] * n_assets)
            
            # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
            result = opt.minimize(
                portfolio_variance,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )
            
            if result.success:
                weights = pd.Series(result.x, index=mu.index)
                
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ
                portfolio_return = portfolio_return(weights)
                portfolio_variance = portfolio_variance(weights)
                portfolio_volatility = np.sqrt(portfolio_variance)
                sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility
                
                # Individual asset contributions
                marginal_contrib = np.dot(cov_matrix.values, weights)
                contrib_percent = weights * marginal_contrib / portfolio_variance
                
                result_dict = {
                    'weights': weights,
                    'expected_return': portfolio_return,
                    'volatility': portfolio_volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'variance': portfolio_variance,
                    'method': 'markowitz',
                    'success': True,
                    'contributions': contrib_percent,
                    'constraints': constraints
                }
                
                self.logger.info(f"Markowitz optimization: Sharpe={sharpe_ratio:.3f}")
                
                return result_dict
            else:
                return {'success': False, 'error': result.message}
                
        except Exception as e:
            self.logger.error(f"Error in Markowitz optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def max_sharpe_optimization(self, returns: pd.DataFrame, 
                               risk_free_rate: float = 0.02) -> Dict[str, any]:
        """
        –ú–∞–∫—Å–∏–º—ñ–∑–∞—Ü—ñ—è Sharpe ratio
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            risk_free_rate: –ë–µ–∑—Ä–∏–∑–∏–∫–æ–≤–∞ —Å—Ç–∞–≤–∫–∞
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            mu = returns.mean() * 252
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            n_assets = len(mu)
            
            # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó (–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π Sharpe)
            def negative_sharpe(weights):
                portfolio_return = np.dot(weights.T, mu)
                portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
                portfolio_volatility = np.sqrt(portfolio_variance)
                
                if portfolio_volatility == 0:
                    return -np.inf
                
                sharpe = (portfolio_return - risk_free_rate) / portfolio_volatility
                return -sharpe
            
            # –û–±–º–µ–∂–µ–Ω–Ω—è
            constraints = [
                {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # –°—É–º–∞ –≤–∞–≥ = 1
            ]
            
            # –ú–µ–∂—ñ –≤–∞–≥
            bounds = tuple((self.constraints['min_weight'], self.constraints['max_weight']) 
                          for _ in range(n_assets))
            
            # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –≤–∞–≥–∏
            x0 = np.array([1/n_assets] * n_assets)
            
            # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
            result = opt.minimize(
                negative_sharpe,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )
            
            if result.success:
                weights = pd.Series(result.x, index=mu.index)
                
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
                portfolio_return = np.dot(weights.T, mu)
                portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
                portfolio_volatility = np.sqrt(portfolio_variance)
                sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility
                
                result_dict = {
                    'weights': weights,
                    'expected_return': portfolio_return,
                    'volatility': portfolio_volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'variance': portfolio_variance,
                    'method': 'max_sharpe',
                    'success': True
                }
                
                self.logger.info(f"Max Sharpe optimization: Sharpe={sharpe_ratio:.3f}")
                
                return result_dict
            else:
                return {'success': False, 'error': result.message}
                
        except Exception as e:
            self.logger.error(f"Error in Max Sharpe optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def risk_parity_optimization(self, returns: pd.DataFrame) -> Dict[str, any]:
        """
        Risk Parity –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (—Ä—ñ–≤–Ω–∏–π —Ä–∏–∑–∏–∫)
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            cov_matrix = self.calculate_covariance_matrix(returns)
            n_assets = len(returns.columns)
            
            # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó - –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—è —Ä—ñ–∑–Ω–∏—Ü—ñ –≤ —Ä–∏–∑–∏–∫–∞—Ö
            def risk_budget_objective(weights):
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ marginal contribution to risk
                portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix.values, weights)))
                marginal_contrib = np.dot(cov_matrix.values, weights) / portfolio_volatility
                contrib = weights * marginal_contrib
                
                # –¶—ñ–ª—å: —Ä—ñ–≤–Ω—ñ –≤–Ω–µ—Å–∫–∏ –≤ —Ä–∏–∑–∏–∫
                target_risk = 1.0 / n_assets
                risk_diff = contrib - target_risk
                
                return np.sum(risk_diff ** 2)
            
            # –û–±–º–µ–∂–µ–Ω–Ω—è
            constraints = [
                {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # –°—É–º–∞ –≤–∞–≥ = 1
            ]
            
            # –ú–µ–∂—ñ –≤–∞–≥
            bounds = tuple((0.01, 1.0) for _ in range(n_assets))  # –ú—ñ–Ω—ñ–º—É–º 1%
            
            # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –≤–∞–≥–∏
            x0 = np.array([1/n_assets] * n_assets)
            
            # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
            result = opt.minimize(
                risk_budget_objective,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )
            
            if result.success:
                weights = pd.Series(result.x, index=returns.columns)
                
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
                mu = returns.mean() * 252
                portfolio_return = np.dot(weights.T, mu)
                portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
                portfolio_volatility = np.sqrt(portfolio_variance)
                sharpe_ratio = portfolio_return / portfolio_volatility
                
                # –†–∏–∑–∏–∫–æ–≤—ñ –≤–Ω–µ—Å–∫–∏
                marginal_contrib = np.dot(cov_matrix.values, weights)
                contrib = weights * marginal_contrib / portfolio_variance
                
                result_dict = {
                    'weights': weights,
                    'expected_return': portfolio_return,
                    'volatility': portfolio_volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'variance': portfolio_variance,
                    'method': 'risk_parity',
                    'success': True,
                    'risk_contributions': contrib
                }
                
                self.logger.info(f"Risk Parity optimization: Sharpe={sharpe_ratio:.3f}")
                
                return result_dict
            else:
                return {'success': False, 'error': result.message}
                
        except Exception as e:
            self.logger.error(f"Error in Risk Parity optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def hierarchical_risk_parity(self, returns: pd.DataFrame) -> Dict[str, any]:
        """
        Hierarchical Risk Parity (HRP)
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            # 1. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –∞–∫—Ç–∏–≤—ñ–≤
            distance_matrix = self._calculate_distance_matrix(cov_matrix)
            linkage_matrix = self._hierarchical_clustering(distance_matrix)
            
            # 2. –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞ –±—ñ–Ω–∞—Ä–Ω–∞ —Ä–æ–∑–±–∏–≤–∫–∞
            clusters = self._get_cluster_order(linkage_matrix)
            
            # 3. –†–æ–∑–ø–æ–¥—ñ–ª –≤–∞–≥
            weights = self._recursive_bisection(cov_matrix, clusters)
            
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
            mu = returns.mean() * 252
            portfolio_return = np.dot(weights.T, mu)
            portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
            portfolio_volatility = np.sqrt(portfolio_variance)
            sharpe_ratio = portfolio_return / portfolio_volatility
            
            result_dict = {
                'weights': pd.Series(weights, index=returns.columns),
                'expected_return': portfolio_return,
                'volatility': portfolio_volatility,
                'sharpe_ratio': sharpe_ratio,
                'variance': portfolio_variance,
                'method': 'hrp',
                'success': True,
                'linkage_matrix': linkage_matrix,
                'clusters': clusters
            }
            
            self.logger.info(f"HRP optimization: Sharpe={sharpe_ratio:.3f}")
            
            return result_dict
            
        except Exception as e:
            self.logger.error(f"Error in HRP optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def black_litterman_optimization(self, returns: pd.DataFrame,
                                   views: Dict[str, float] = None,
                                   tau: float = 0.025,
                                   risk_free_rate: float = 0.02) -> Dict[str, any]:
        """
        Black-Litterman –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            views: –î—É–º–∫–∏ —ñ–Ω–≤–µ—Å—Ç–æ—Ä–∞ (views)
            tau: –ü–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ
            risk_free_rate: –ë–µ–∑—Ä–∏–∑–∏–∫–æ–≤–∞ —Å—Ç–∞–≤–∫–∞
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            mu = returns.mean() * 252
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            n_assets = len(mu)
            
            # –†–∏–Ω–∫–æ–≤—ñ –≤–∞–≥–∏ (—Ä—ñ–≤–Ω—ñ —è–∫ –±–∞–∑–∞)
            market_weights = np.array([1/n_assets] * n_assets)
            
            # –†–∏–Ω–∫–æ–≤—ñ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ (implied returns)
            risk_aversion = 3.0  # –¢–∏–ø–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è
            implied_returns = risk_aversion * np.dot(cov_matrix.values, market_weights)
            
            # –Ø–∫—â–æ –Ω–µ–º–∞—î –¥—É–º–æ–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ implied returns
            if views is None:
                # –°—Ç–≤–æ—Ä—é—î–º–æ –±–∞–∑–æ–≤—ñ –¥—É–º–∫–∏ (—Ä—ñ–≤–Ω—ñ –¥–æ —Ä–∏–Ω–∫—É)
                views = {}
                for asset in mu.index:
                    views[asset] = implied_returns[mu.index.get_loc(asset)]
            
            # –ú–∞—Ç—Ä–∏—Ü—è –¥—É–º–æ–∫
            P = np.eye(n_assets)  # –ü—Ä–æ—Å—Ç–∏–π –≤–∏–ø–∞–¥–æ–∫ - –∫–æ–∂–Ω–∞ –¥—É–º–∫–∞ –ø—Ä–æ –æ–¥–∏–Ω –∞–∫—Ç–∏–≤
            Q = np.array([views.get(asset, implied_returns[i]) for i, asset in enumerate(mu.index)])
            
            # Black-Litterman —Ñ–æ—Ä–º—É–ª–∞
            tau_cov = tau * cov_matrix.values
            omega = tau * np.eye(n_assets)  # –°–ø—Ä–æ—â–µ–Ω–Ω—è
            
            # –û–±–µ—Ä–Ω–µ–Ω—ñ –º–∞—Ç—Ä–∏—Ü—ñ
            tau_cov_inv = np.linalg.inv(tau_cov)
            omega_inv = np.linalg.inv(omega)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ blended returns
            posterior_returns = np.linalg.inv(
                tau_cov_inv + P.T @ omega_inv @ P
            ) @ (tau_cov_inv @ implied_returns + P.T @ omega_inv @ Q)
            
            # –û–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
            posterior_cov = cov_matrix.values + tau_cov
            
            # Markowitz –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –∑ blended returns
            def portfolio_variance(weights):
                return np.dot(weights.T, np.dot(posterior_cov, weights))
            
            def portfolio_return(weights):
                return np.dot(weights.T, posterior_returns)
            
            # –û–±–º–µ–∂–µ–Ω–Ω—è
            constraints = [
                {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}
            ]
            
            # –ú–µ–∂—ñ –≤–∞–≥
            bounds = tuple((self.constraints['min_weight'], self.constraints['max_weight']) 
                          for _ in range(n_assets))
            
            # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –≤–∞–≥–∏
            x0 = np.array([1/n_assets] * n_assets)
            
            # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
            result = opt.minimize(
                portfolio_variance,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )
            
            if result.success:
                weights = pd.Series(result.x, index=mu.index)
                
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
                portfolio_return = portfolio_return(weights)
                portfolio_variance = portfolio_variance(weights)
                portfolio_volatility = np.sqrt(portfolio_variance)
                sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility
                
                result_dict = {
                    'weights': weights,
                    'expected_return': portfolio_return,
                    'volatility': portfolio_volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'variance': portfolio_variance,
                    'method': 'black_litterman',
                    'success': True,
                    'implied_returns': pd.Series(implied_returns, index=mu.index),
                    'posterior_returns': pd.Series(posterior_returns, index=mu.index),
                    'views': views
                }
                
                self.logger.info(f"Black-Litterman optimization: Sharpe={sharpe_ratio:.3f}")
                
                return result_dict
            else:
                return {'success': False, 'error': result.message}
                
        except Exception as e:
            self.logger.error(f"Error in Black-Litterman optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def equal_weight_portfolio(self, returns: pd.DataFrame) -> Dict[str, any]:
        """
        –†—ñ–≤–Ω–æ–≤–∞–≥–æ–≤–∏–π –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            n_assets = len(returns.columns)
            weights = np.array([1/n_assets] * n_assets)
            
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
            mu = returns.mean() * 252
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            portfolio_return = np.dot(weights.T, mu)
            portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
            portfolio_volatility = np.sqrt(portfolio_variance)
            sharpe_ratio = portfolio_return / portfolio_volatility
            
            result_dict = {
                'weights': pd.Series(weights, index=returns.columns),
                'expected_return': portfolio_return,
                'volatility': portfolio_volatility,
                'sharpe_ratio': sharpe_ratio,
                'variance': portfolio_variance,
                'method': 'equal_weight',
                'success': True
            }
            
            self.logger.info(f"Equal weight portfolio: Sharpe={sharpe_ratio:.3f}")
            
            return result_dict
            
        except Exception as e:
            self.logger.error(f"Error in equal weight portfolio: {e}")
            return {'success': False, 'error': str(e)}
    
    def inverse_volatility_portfolio(self, returns: pd.DataFrame) -> Dict[str, any]:
        """
        –ü–æ—Ä—Ç—Ñ–æ–ª—ñ–æ –∑ –æ–±–µ—Ä–Ω–µ–Ω–æ—é –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—é
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ
            volatilities = returns.std() * np.sqrt(252)
            
            # –û–±–µ—Ä–Ω–µ–Ω—ñ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ
            inv_vols = 1 / volatilities
            
            # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –≤–∞–≥–∏
            weights = inv_vols / inv_vols.sum()
            
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
            mu = returns.mean() * 252
            cov_matrix = self.calculate_covariance_matrix(returns)
            
            portfolio_return = np.dot(weights.T, mu)
            portfolio_variance = np.dot(weights.T, np.dot(cov_matrix.values, weights))
            portfolio_volatility = np.sqrt(portfolio_variance)
            sharpe_ratio = portfolio_return / portfolio_volatility
            
            result_dict = {
                'weights': pd.Series(weights, index=returns.columns),
                'expected_return': portfolio_return,
                'volatility': portfolio_volatility,
                'sharpe_ratio': sharpe_ratio,
                'variance': portfolio_variance,
                'method': 'inverse_volatility',
                'success': True
            }
            
            self.logger.info(f"Inverse volatility portfolio: Sharpe={sharpe_ratio:.3f}")
            
            return result_dict
            
        except Exception as e:
            self.logger.error(f"Error in inverse volatility portfolio: {e}")
            return {'success': False, 'error': str(e)}
    
    def optimize_portfolio(self, returns: pd.DataFrame, 
                         method: str = 'max_sharpe',
                         **kwargs) -> Dict[str, any]:
        """
        –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ –≤–∫–∞–∑–∞–Ω–∏–º –º–µ—Ç–æ–¥–æ–º
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            method: –ú–µ—Ç–æ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            **kwargs: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        """
        try:
            if method == 'markowitz':
                return self.markowitz_optimization(returns, **kwargs)
            elif method == 'max_sharpe':
                return self.max_sharpe_optimization(returns, **kwargs)
            elif method == 'min_variance':
                return self.markowitz_optimization(returns, target_return=0, **kwargs)
            elif method == 'risk_parity':
                return self.risk_parity_optimization(returns, **kwargs)
            elif method == 'hrp':
                return self.hierarchical_risk_parity(returns, **kwargs)
            elif method == 'black_litterman':
                return self.black_litterman_optimization(returns, **kwargs)
            elif method == 'equal_weight':
                return self.equal_weight_portfolio(returns, **kwargs)
            elif method == 'inverse_volatility':
                return self.inverse_volatility_portfolio(returns, **kwargs)
            else:
                return {'success': False, 'error': f'Unknown method: {method}'}
                
        except Exception as e:
            self.logger.error(f"Error in portfolio optimization: {e}")
            return {'success': False, 'error': str(e)}
    
    def compare_optimization_methods(self, returns: pd.DataFrame) -> Dict[str, Dict]:
        """
        –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ —Ä—ñ–∑–Ω—ñ –º–µ—Ç–æ–¥–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        
        Args:
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—Å—ñ—Ö –º–µ—Ç–æ–¥—ñ–≤
        """
        try:
            results = {}
            
            for method in self.optimization_methods:
                result = self.optimize_portfolio(returns, method=method)
                results[method] = result
                
                if result.get('success', False):
                    self.logger.info(f"{method}: Sharpe={result.get('sharpe_ratio', 0):.3f}")
                else:
                    self.logger.warning(f"{method}: Failed - {result.get('error', 'Unknown error')}")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–ª–∏—Ü—é –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
            comparison = self._create_comparison_table(results)
            
            return {'results': results, 'comparison': comparison}
            
        except Exception as e:
            self.logger.error(f"Error comparing optimization methods: {e}")
            return {}
    
    # Helper methods
    def _calculate_ledoit_wolf_shrinkage(self, returns: pd.DataFrame) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ shrinkage intensity –¥–ª—è Ledoit-Wolf"""
        try:
            n, p = returns.shape
            sample_cov = returns.cov()
            
            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            var_diag = np.diag(sample_cov)
            rho = np.mean(sample_cov.values[np.triu_indices_from(sample_cov.values, k=1)])
            
            # Pi matrix
            pi = np.zeros((p, p))
            for i in range(p):
                for j in range(p):
                    if i != j:
                        pi[i, j] = (returns.iloc[:, i] * returns.iloc[:, j]).mean() - \
                                  returns.iloc[:, i].mean() * returns.iloc[:, j].mean()
            
            # Shrinkage intensity
            pi_sum = np.sum(pi ** 2)
            theta_sum = np.sum((sample_cov.values - rho * np.eye(p)) ** 2)
            
            shrinkage = max(0, min(1, pi_sum / theta_sum))
            
            return shrinkage
            
        except Exception as e:
            self.logger.error(f"Error calculating Ledoit-Wolf shrinkage: {e}")
            return 0.0
    
    def _ensure_positive_definite(self, cov_matrix: pd.DataFrame) -> pd.DataFrame:
        """–ó–∞without–ø–µ—á–∏—Ç–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—É –≤–∏–∑–Ω–∞—á–µ–Ω—ñ—Å—Ç—å –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–æ—ó –º–∞—Ç—Ä–∏—Ü—ñ"""
        try:
            eigenvalues = np.linalg.eigvals(cov_matrix.values)
            
            if np.all(eigenvalues > 0):
                return cov_matrix
            
            # –î–æ–¥–∞—î–º–æ –Ω–µ–≤–µ–ª–∏–∫–∏–π —à—É–º –¥–æ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ
            min_eigenvalue = np.min(eigenvalues)
            if min_eigenvalue < 0:
                noise = abs(min_eigenvalue) + 1e-8
                cov_matrix_fixed = cov_matrix.copy()
                np.fill_diagonal(cov_matrix_fixed.values, 
                                np.diag(cov_matrix_fixed.values) + noise)
                return cov_matrix_fixed
            
            return cov_matrix
            
        except Exception as e:
            self.logger.error(f"Error ensuring positive definite: {e}")
            return cov_matrix
    
    def _calculate_distance_matrix(self, cov_matrix: pd.DataFrame) -> np.ndarray:
        """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –≤—ñ–¥—Å—Ç–∞–Ω–µ–π –¥–ª—è HRP"""
        try:
            # Correlation matrix
            corr_matrix = cov_matrix.corr()
            
            # Distance matrix
            distance_matrix = np.sqrt(0.5 * (1 - corr_matrix))
            
            return distance_matrix.values
            
        except Exception as e:
            self.logger.error(f"Error calculating distance matrix: {e}")
            return np.zeros((len(cov_matrix), len(cov_matrix)))
    
    def _hierarchical_clustering(self, distance_matrix: np.ndarray) -> np.ndarray:
        """–Ü—î—Ä–∞—Ä—Ö—ñ—á–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è"""
        try:
            from scipy.cluster.hierarchy import linkage
            
            # Flatten distance matrix for linkage
            condensed_distance = []
            n = distance_matrix.shape[0]
            
            for i in range(n):
                for j in range(i + 1, n):
                    condensed_distance.append(distance_matrix[i, j])
            
            linkage_matrix = linkage(condensed_distance, method='single')
            
            return linkage_matrix
            
        except Exception as e:
            self.logger.error(f"Error in hierarchical clustering: {e}")
            return np.array([])
    
    def _get_cluster_order(self, linkage_matrix: np.ndarray) -> List[int]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø–æ—Ä—è–¥–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤"""
        try:
            from scipy.cluster.hierarchy import dendrogram
            
            # Get dendrogram
            dendro = dendrogram(linkage_matrix, no_plot=True)
            
            # Get leaf order
            leaf_order = dendro['leaves']
            
            return leaf_order
            
        except Exception as e:
            self.logger.error(f"Error getting cluster order: {e}")
            return list(range(len(linkage_matrix) + 1))
    
    def _recursive_bisection(self, cov_matrix: pd.DataFrame, clusters: List[int]) -> np.ndarray:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–∞ –±—ñ—Å–µ–∫—Ü—ñ—è –¥–ª—è HRP"""
        try:
            n_assets = len(cov_matrix)
            weights = np.zeros(n_assets)
            
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º
            def allocate_cluster(cluster_indices, cluster_weight):
                if len(cluster_indices) == 1:
                    weights[cluster_indices[0]] = cluster_weight
                else:
                    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –∫–ª–∞—Å—Ç–µ—Ä
                    cluster_cov = cov_matrix.iloc[cluster_indices, cluster_indices]
                    cluster_var = np.diag(cluster_cov)
                    
                    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –≤–∞–≥—É –ø—Ä–æ–ø–æ—Ä—Ü—ñ–π–Ω–æ –¥–æ –æ–±–µ—Ä–Ω–µ–Ω–æ—ó –¥–∏—Å–ø–µ—Ä—Å—ñ—ó
                    inv_var = 1 / cluster_var
                    sub_weights = inv_var / inv_var.sum()
                    
                    for i, idx in enumerate(cluster_indices):
                        weights[idx] = cluster_weight * sub_weights[i]
            
            # –ü–æ—á–∏–Ω–∞—î–º–æ –∑ –ø–æ–≤–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
            allocate_cluster(clusters, 1.0)
            
            return weights
            
        except Exception as e:
            self.logger.error(f"Error in recursive bisection: {e}")
            return np.ones(len(cov_matrix)) / len(cov_matrix)
    
    def _create_comparison_table(self, results: Dict[str, Dict]) -> pd.DataFrame:
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∞–±–ª–∏—Ü—é –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤"""
        try:
            comparison_data = []
            
            for method, result in results.items():
                if result.get('success', False):
                    comparison_data.append({
                        'Method': method,
                        'Expected Return': result.get('expected_return', 0),
                        'Volatility': result.get('volatility', 0),
                        'Sharpe Ratio': result.get('sharpe_ratio', 0),
                        'Success': True
                    })
                else:
                    comparison_data.append({
                        'Method': method,
                        'Expected Return': 0,
                        'Volatility': 0,
                        'Sharpe Ratio': 0,
                        'Success': False
                    })
            
            comparison_df = pd.DataFrame(comparison_data)
            comparison_df = comparison_df.sort_values('Sharpe Ratio', ascending=False)
            
            return comparison_df
            
        except Exception as e:
            self.logger.error(f"Error creating comparison table: {e}")
            return pd.DataFrame()


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä
portfolio_optimizer = PortfolioOptimizer()


def optimize_portfolio(returns: pd.DataFrame, method: str = 'max_sharpe', **kwargs) -> Dict[str, any]:
    """–û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ"""
    return portfolio_optimizer.optimize_portfolio(returns, method, **kwargs)


def compare_portfolio_methods(returns: pd.DataFrame) -> Dict[str, Dict]:
    """–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –º–µ—Ç–æ–¥–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ"""
    return portfolio_optimizer.compare_optimization_methods(returns)


if __name__ == "__main__":
    # –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
    logging.basicConfig(level=logging.INFO)
    
    print("üíº Portfolio Optimizer Test")
    print("="*50)
    
    # –°–∏–º—É–ª—è—Ü—ñ—è data
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', '2024-01-01', freq='D')
    
    # –°–∏–º—É–ª—è—Ü—ñ—è —Ü—ñ–Ω 5 –∞–∫—Ç–∏–≤—ñ–≤
    assets = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']
    prices = pd.DataFrame(index=dates, columns=assets)
    
    for asset in assets:
        # –†—ñ–∑–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É
        drift = np.random.uniform(0.0001, 0.0015)
        volatility = np.random.uniform(0.015, 0.035)
        
        prices[asset] = 100 * np.exp(np.cumsum(
            np.random.normal(drift, volatility, len(dates))
        ))
    
    # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
    returns = prices.pct_change().dropna()
    
    # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –º–µ—Ç–æ–¥–∏
    comparison = compare_portfolio_methods(returns)
    
    if 'comparison' in comparison:
        print(f"[DATA] Portfolio Optimization Comparison:")
        print(comparison['comparison'].round(4))
        
        # –ù–∞–π–∫—Ä–∞—â–∏–π –º–µ—Ç–æ–¥
        best_method = comparison['comparison'].iloc[0]['Method']
        print(f"\n[WIN] Best Method: {best_method}")
        
        # –î–µ—Ç–∞–ª—ñ –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –º–µ—Ç–æ–¥—É
        best_result = comparison['results'][best_method]
        if best_result.get('success', False):
            print(f"   Expected Return: {best_result['expected_return']:.2%}")
            print(f"   Volatility: {best_result['volatility']:.2%}")
            print(f"   Sharpe Ratio: {best_result['sharpe_ratio']:.3f}")
            
            # –¢–æ–ø 5 –≤–∞–≥
            weights = best_result['weights'].sort_values(ascending=False)
            print(f"   Top 5 Weights:")
            for asset, weight in weights.head().items():
                print(f"     {asset}: {weight:.2%}")
        
        print(f"\n[OK] Portfolio Optimization working correctly!")
    else:
        print(f"[ERROR] Comparison failed")
